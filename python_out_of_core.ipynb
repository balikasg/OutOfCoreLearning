{
 "metadata": {
  "name": "",
  "signature": "sha256:40fa01c19d53166548243a83b1f06587954a997b832efe2f06a82f598ab0c967"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn import svm, cross_validation, preprocessing, grid_search\n",
      "from sklearn.feature_extraction.text import CountVectorizer, HashingVectorizer\n",
      "import matplotlib.pyplot as plt, numpy as np, seaborn as sns, codecs, sys, json\n",
      "\n",
      "#Load data\n",
      "data = open('data/text_500classes.txt').read().splitlines()\n",
      "y = [int(z) for z in open('./data/labels_500classes.txt').read().splitlines()]\n",
      "vectorized_data = CountVectorizer().fit_transform(data)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Apply two different vctorizers and report 5-cv scores for Linear SVMs and different values of the regularization param.\n",
      "for fraction in np.arange(0.05, 1, 0.1):\n",
      "    vec = HashingVectorizer(n_features=int(len(data)*fraction))\n",
      "    vectorized_data = vec.fit_transform(data)\n",
      "    print \"Data Shape:\", vectorized_data.shape\n",
      "    vectorized_data = preprocessing.Normalizer().fit_transform(vectorized_data.astype(np.float))\n",
      "    scores = cross_validation.cross_val_score(svm.LinearSVC(C=1), vectorized_data, y, cv=5, n_jobs=3)\n",
      "    print \"5-CV classification score when the feature space is %f%% of the total:\"%(fraction*100), np.average(scores), np.std(scores)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Data Shape: (38448, 1922)\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "/home/balikasg/anaconda/lib/python2.7/site-packages/sklearn/cross_validation.py:417: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of labels for any class cannot be less than n_folds=5.\n",
        "  % (min_labels, self.n_folds)), Warning)\n"
       ]
      }
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Calculate SGD performance with SVM settings \n",
      "from sklearn import linear_model\n",
      "X_train, X_test, y_train, y_test = cross_validation.train_test_split(vectorized_data, y, test_size=0.3, random_state=42)\n",
      "clf = linear_model.SGDClassifier(loss='hinge', penalty='l2')\n",
      "clf.fit(X_train, y_train)\n",
      "sgd_perf = clf.score(X_test, y_test)\n",
      "print \"Score with standard learning:\", sgd_perf \n",
      "all_classes = list(set(y))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 0
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Calculate SGD with SVM settings and partial fit\n",
      "def batch(inputData, y, n=1):\n",
      "    \"\"\" This function, given data returns batches of maximum length n\"\"\"\n",
      "    l = inputData.shape[0]\n",
      "    for ndx in range(0, l, n):\n",
      "        yield inputData[ndx:min(ndx + n, l)], y[ndx:min(ndx + n, l)]\n",
      "\n",
      "score2plot=[]\n",
      "batch_sizes = [1000, 5000, 10000, 15000, 20000, 26914]\n",
      "for batch_size in batch_sizes:\n",
      "    clf = linear_model.SGDClassifier(loss='hinge', penalty='l2')\n",
      "    for i in range(10): #Ensure fitting the data\n",
      "        for batch_train, batch_y_train in batch(X_train,y_train, n=batch_size):\n",
      "            clf.partial_fit(batch_train, batch_y_train, classes=all_classes)\n",
      "    score2plot.append(clf.score(X_test, y_test))\n",
      "    print \"Score with online learning (batch size=%d):\"%batch_size, clf.score(X_test, y_test)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 0
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Calculate tuned SVM performance\n",
      "clf = grid_search.GridSearchCV(svm.LinearSVC(), param_grid={'C':[0.1, 1, 10, 100]}, n_jobs=-1, refit=True, cv=3)\n",
      "clf.fit(X_train, y_train)\n",
      "svm_perf = clf.score(X_test, y_test)\n",
      "print \"SVM score with hyper-parameter tuning:\", svm_perf"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 0
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "xx = range(100, 100*len(batch_sizes)+1, 100)\n",
      "%matplotlib inline\n",
      "fig, axes = plt.subplots(nrows=1, ncols=1, figsize=(6, 4), )\n",
      "axes.plot(xx, score2plot, \"-o\", label='Partial fit')\n",
      "axes.plot(xx, [svm_perf]*len(xx), \"r-x\", label='Tuned SVM')\n",
      "axes.plot(xx, [sgd_perf]*len(xx), \"-gx\", label='Stoch. GD, complete data')\n",
      "axes.set_ylabel(\"Accuracy on Test Data, 30% split\")\n",
      "axes.set_xlabel(\"Batch size\")\n",
      "axes.set_xticklabels(batch_sizes)\n",
      "axes.legend(loc=4)\n",
      "plt.tight_layout()\n",
      "axes.set_ylim([0.6, 0.72])\n",
      "axes.set_xlim([xx[0]-30, xx[-1]+30])\n",
      "# plt.savefig('patrialFitEffect.pdf', bbox_inches='tight',)\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 0
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 0
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}